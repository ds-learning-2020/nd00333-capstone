{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment, Datastore, Dataset\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy, MedianStoppingPolicy\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import uniform, normal, choice\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.environment import Environment\n",
        "\n",
        "import os\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import sys\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1605196790442
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
        "\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'capstone-automl'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1605193878425
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Corona_NLP_train.csv\")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1605193878751
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "  Unnamed: 0 UserName  ScreenName   Location     TweetAt  \\\n0          0     3799     48751.0     London  16-03-2020   \n1          1     3800     48752.0         UK  16-03-2020   \n2          2     3801     48753.0  Vagabonds  16-03-2020   \n3          3     3802     48754.0        NaN  16-03-2020   \n4          4     3803     48755.0        NaN  16-03-2020   \n\n                                       OriginalTweet           Sentiment  \n0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n1  advice Talk to your neighbours family to excha...            Positive  \n2  Coronavirus Australia: Woolworths to give elde...            Positive  \n3  My food stock is not the only one which is emp...            Positive  \n4  Me, ready to go at supermarket during the #COV...  Extremely Negative  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3799</td>\n      <td>48751.0</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3800</td>\n      <td>48752.0</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3801</td>\n      <td>48753.0</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>Coronavirus Australia: Woolworths to give elde...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3802</td>\n      <td>48754.0</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>My food stock is not the only one which is emp...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>3803</td>\n      <td>48755.0</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>Me, ready to go at supermarket during the #COV...</td>\n      <td>Extremely Negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1605193878947
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.Sentiment.unique()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "array(['Neutral', 'Positive', 'Extremely Negative', 'Negative',\n       'Extremely Positive', nan], dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1605193879153
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 41159 entries, 0 to 41158\n",
            "Data columns (total 7 columns):\n",
            "Unnamed: 0       41158 non-null object\n",
            "UserName         41158 non-null object\n",
            "ScreenName       41157 non-null float64\n",
            "Location         32567 non-null object\n",
            "TweetAt          41157 non-null object\n",
            "OriginalTweet    41157 non-null object\n",
            "Sentiment        41155 non-null object\n",
            "dtypes: float64(1), object(6)\n",
            "memory usage: 2.2+ MB\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1605193879321
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_modified = df[[\"OriginalTweet\", \"Sentiment\"]].copy()\n",
        "df_modified[\"OriginalTweet\"] = df_modified[\"OriginalTweet\"].astype(\"str\")\n",
        "df_modified[\"Sentiment\"] = df_modified[\"Sentiment\"].astype(\"str\")\n",
        "df_modified = df_modified[df_modified[\"Sentiment\"] != \"nan\"]\n",
        "\n",
        "       \n",
        "positive = df_modified[\"Sentiment\"].isin([\"Neutral\", \"Positive\", 'Extremely Positive'])\n",
        "negative = df_modified[\"Sentiment\"].isin(['Extremely Negative', 'Negative'])\n",
        "\n",
        "df_modified.loc[positive, \"Sentiment\"] = 1\n",
        "df_modified.loc[negative, \"Sentiment\"] = 0\n",
        "\n",
        "df_modified[\"Sentiment\"] = df_modified[\"Sentiment\"].astype(\"int\")"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1605193879384
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_modified[\"Sentiment\"].unique()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "array([1, 0])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1605193879570
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_modified.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "                                       OriginalTweet  Sentiment\n0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...          1\n1  advice Talk to your neighbours family to excha...          1\n2  Coronavirus Australia: Woolworths to give elde...          1\n3  My food stock is not the only one which is emp...          1\n4  Me, ready to go at supermarket during the #COV...          0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Coronavirus Australia: Woolworths to give elde...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>My food stock is not the only one which is emp...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Me, ready to go at supermarket during the #COV...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1605193879757
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_modified.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 41155 entries, 0 to 41158\n",
            "Data columns (total 2 columns):\n",
            "OriginalTweet    41155 non-null object\n",
            "Sentiment        41155 non-null int64\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 964.6+ KB\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1605193879822
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\r\n",
        "# fix dependency issue\r\n",
        "!{sys.executable} -m pip install zipp==3.1.0\r\n",
        "!{sys.executable} -m pip install cryptography==3.1.1"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: zipp==3.1.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (3.1.0)\n",
            "Requirement already satisfied: cryptography==3.1.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (3.1.1)\n",
            "Requirement already satisfied: six>=1.4.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from cryptography==3.1.1) (1.15.0)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from cryptography==3.1.1) (1.14.3)\n",
            "Requirement already satisfied: pycparser in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography==3.1.1) (2.20)\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605193885447
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Put your automl settings here\n",
        "automl_settings = {\"experiment_timeout_minutes\":30,\n",
        "    \"task\":\"classification\",\n",
        "    \"primary_metric\":\"accuracy\",\n",
        "    \"training_data\":df_modified,\n",
        "    \"label_column_name\":\"Sentiment\",\n",
        "    \"n_cross_validations\":3}\n",
        "\n",
        "# TODO: Put your automl config here\n",
        "automl_config = AutoMLConfig(**automl_settings)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1605193885663
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit Experiment & Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Submit your experiment\n",
        "automl_run = experiment.submit(automl_config, show_output=True)\n",
        "RunDetails(automl_run).show()\n",
        "automl_run.wait_for_completion(show_output=False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on local machine\n",
            "Parent Run ID: AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\n",
            "\n",
            "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
            "Current status: FeaturesGeneration. Generating features for the dataset.\n",
            "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
            "Current status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\n",
            "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
            "\n",
            "********************************************************************************************************************\n",
            "DATA GUARDRAILS: \n",
            "\n",
            "TYPE:         Class balancing detection\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  Your inputs were analyzed, and all classes are balanced in your training data.\n",
            "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
            "\n",
            "********************************************************************************************************************\n",
            "\n",
            "TYPE:         Missing feature values imputation\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  No feature missing values were detected in the training data.\n",
            "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
            "\n",
            "********************************************************************************************************************\n",
            "\n",
            "TYPE:         High cardinality feature detection\n",
            "STATUS:       DONE\n",
            "DESCRIPTION:  High cardinality features were detected in your inputs and handled.\n",
            "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
            "DETAILS:      High cardinality features refer to columns that contain a large percentage of unique values.\n",
            "+--------------------------------------+--------------------------------------+\n",
            "|Column name                           |Column Content Type                   |\n",
            "+======================================+======================================+\n",
            "|OriginalTweet                         |text                                  |\n",
            "+--------------------------------------+--------------------------------------+\n",
            "\n",
            "********************************************************************************************************************\n",
            "Current status: ModelSelection. Beginning model selection.\n",
            "\n",
            "********************************************************************************************************************\n",
            "ITERATION: The iteration being evaluated.\n",
            "PIPELINE: A summary description of the pipeline being evaluated.\n",
            "SAMPLING %: Percent of the training data to sample.\n",
            "DURATION: Time taken for the current iteration.\n",
            "METRIC: The result of computing score on the fitted pipeline.\n",
            "BEST: The best observed score thus far.\n",
            "********************************************************************************************************************\n",
            "\n",
            " ITERATION   PIPELINE                                       SAMPLING %  DURATION      METRIC      BEST\n",
            "         0   MaxAbsScaler LightGBM                          5.0000      0:05:22       0.7087    0.7087\n",
            "         1   MaxAbsScaler XGBoostClassifier                 5.0000      0:11:51       0.7044    0.7087\n",
            "         2   MaxAbsScaler RandomForest                      5.0000      0:02:12       0.6267    0.7087\n",
            "         3   MaxAbsScaler RandomForest                      5.0000      0:02:18       0.6259    0.7087\n",
            "         4   MaxAbsScaler SGD                               5.0000      0:02:18       0.7079    0.7087\n",
            "         5   MaxAbsScaler SGD                               5.0000      0:02:22       0.7058    0.7087\n",
            "         6   VotingEnsemble                                 100.0000    0:01:58       0.7221    0.7221\n",
            "         7   StackEnsemble                                  100.0000    0:02:02       0.7213    0.7221\n",
            "Stopping criteria reached at iteration 8. Ending experiment.\n",
            "********************************************************************************************************************\n",
            "Current status: BestRunExplainModel. Best run model explanations started\n",
            "Current status: ModelExplanationDataSetSetup. Model explanations data setup completed\n",
            "Current status: PickSurrogateModel. Choosing LinearModel as the surrogate model for explanations\n",
            "Current status: EngineeredFeatureExplanations. Computation of engineered features started\n",
            "Current status: EngineeredFeatureExplanations. Computation of engineered features completed\n",
            "Current status: BestRunExplainModel. Best run model explanations completed\n",
            "********************************************************************************************************************\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 's…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47cd6cedbab44bf38e0ad70cfa828c96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/capstone-automl/runs/AutoML_abbda561-5be6-424f-8561-456ebc80c7c0?wsid=/subscriptions/174c6bee-3e04-4ee5-98ea-6d411844e6dd/resourcegroups/aml-quickstarts-125813/workspaces/quick-starts-ws-125813\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"run_properties\": {\"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"created_utc\": \"2020-11-12T15:12:18.349873Z\", \"properties\": {\"num_iterations\": \"1000\", \"training_type\": \"TrainFull\", \"acquisition_function\": \"EI\", \"primary_metric\": \"accuracy\", \"train_split\": \"0\", \"acquisition_parameter\": \"0\", \"num_cross_validation\": \"3\", \"target\": \"local\", \"AMLSettingsJsonString\": \"{\\\"path\\\":null,\\\"name\\\":\\\"capstone-automl\\\",\\\"subscription_id\\\":\\\"174c6bee-3e04-4ee5-98ea-6d411844e6dd\\\",\\\"resource_group\\\":\\\"aml-quickstarts-125813\\\",\\\"workspace_name\\\":\\\"quick-starts-ws-125813\\\",\\\"region\\\":\\\"southcentralus\\\",\\\"compute_target\\\":\\\"local\\\",\\\"spark_service\\\":null,\\\"azure_service\\\":\\\"Microsoft.AzureNotebookVM\\\",\\\"_local_managed_run_id\\\":null,\\\"many_models\\\":false,\\\"pipeline_fetch_max_batch_size\\\":1,\\\"iterations\\\":1000,\\\"primary_metric\\\":\\\"accuracy\\\",\\\"task_type\\\":\\\"classification\\\",\\\"data_script\\\":null,\\\"validation_size\\\":0.0,\\\"n_cross_validations\\\":3,\\\"y_min\\\":null,\\\"y_max\\\":null,\\\"num_classes\\\":2,\\\"featurization\\\":\\\"auto\\\",\\\"_ignore_package_version_incompatibilities\\\":false,\\\"is_timeseries\\\":false,\\\"max_cores_per_iteration\\\":1,\\\"max_concurrent_iterations\\\":1,\\\"iteration_timeout_minutes\\\":null,\\\"mem_in_mb\\\":null,\\\"enforce_time_on_windows\\\":false,\\\"experiment_timeout_minutes\\\":30,\\\"experiment_exit_score\\\":null,\\\"whitelist_models\\\":null,\\\"blacklist_algos\\\":[\\\"TensorFlowLinearClassifier\\\",\\\"TensorFlowDNN\\\"],\\\"supported_models\\\":[\\\"SGD\\\",\\\"BernoulliNaiveBayes\\\",\\\"LightGBM\\\",\\\"LogisticRegression\\\",\\\"DecisionTree\\\",\\\"GradientBoosting\\\",\\\"TensorFlowDNN\\\",\\\"RandomForest\\\",\\\"KNN\\\",\\\"TensorFlowLinearClassifier\\\",\\\"XGBoostClassifier\\\",\\\"MultinomialNaiveBayes\\\",\\\"LinearSVM\\\",\\\"AveragedPerceptronClassifier\\\",\\\"ExtremeRandomTrees\\\",\\\"SVM\\\"],\\\"auto_blacklist\\\":true,\\\"blacklist_samples_reached\\\":false,\\\"exclude_nan_labels\\\":true,\\\"verbosity\\\":20,\\\"_debug_log\\\":\\\"automl.log\\\",\\\"show_warnings\\\":false,\\\"model_explainability\\\":true,\\\"service_url\\\":null,\\\"sdk_url\\\":null,\\\"sdk_packages\\\":null,\\\"enable_onnx_compatible_models\\\":false,\\\"enable_split_onnx_featurizer_estimator_models\\\":false,\\\"vm_type\\\":null,\\\"telemetry_verbosity\\\":20,\\\"send_telemetry\\\":true,\\\"enable_dnn\\\":false,\\\"force_text_dnn\\\":false,\\\"enable_feature_sweeping\\\":true,\\\"enable_early_stopping\\\":false,\\\"early_stopping_n_iters\\\":10,\\\"metrics\\\":null,\\\"enable_ensembling\\\":true,\\\"enable_stack_ensembling\\\":true,\\\"ensemble_iterations\\\":15,\\\"enable_tf\\\":false,\\\"enable_subsampling\\\":null,\\\"subsample_seed\\\":null,\\\"enable_nimbusml\\\":false,\\\"enable_streaming\\\":false,\\\"force_streaming\\\":false,\\\"track_child_runs\\\":true,\\\"allowed_private_models\\\":[],\\\"label_column_name\\\":\\\"Sentiment\\\",\\\"weight_column_name\\\":null,\\\"cv_split_column_names\\\":null,\\\"enable_local_managed\\\":false,\\\"cost_mode\\\":1,\\\"lag_length\\\":0,\\\"metric_operation\\\":\\\"maximize\\\",\\\"preprocess\\\":true,\\\"scenario\\\":\\\"SDK-1.13.0\\\"}\", \"DataPrepJsonString\": null, \"EnableSubsampling\": null, \"runTemplate\": \"AutoML\", \"azureml.runsource\": \"automl\", \"display_task_type\": \"classification\", \"dependencies_versions\": \"{\\\"azureml-widgets\\\": \\\"1.17.0\\\", \\\"azureml-train\\\": \\\"1.17.0\\\", \\\"azureml-train-restclients-hyperdrive\\\": \\\"1.17.0\\\", \\\"azureml-train-core\\\": \\\"1.17.0\\\", \\\"azureml-train-automl\\\": \\\"1.17.0\\\", \\\"azureml-train-automl-runtime\\\": \\\"1.17.0\\\", \\\"azureml-train-automl-client\\\": \\\"1.17.0\\\", \\\"azureml-tensorboard\\\": \\\"1.17.0\\\", \\\"azureml-telemetry\\\": \\\"1.17.0\\\", \\\"azureml-sdk\\\": \\\"1.17.0\\\", \\\"azureml-samples\\\": \\\"0+unknown\\\", \\\"azureml-pipeline\\\": \\\"1.17.0\\\", \\\"azureml-pipeline-steps\\\": \\\"1.17.0\\\", \\\"azureml-pipeline-core\\\": \\\"1.17.0\\\", \\\"azureml-opendatasets\\\": \\\"1.17.0\\\", \\\"azureml-model-management-sdk\\\": \\\"1.0.1b6.post1\\\", \\\"azureml-mlflow\\\": \\\"1.17.0.post1\\\", \\\"azureml-interpret\\\": \\\"1.17.0\\\", \\\"azureml-explain-model\\\": \\\"1.17.0\\\", \\\"azureml-defaults\\\": \\\"1.17.0\\\", \\\"azureml-dataset-runtime\\\": \\\"1.17.0\\\", \\\"azureml-dataprep\\\": \\\"2.4.2\\\", \\\"azureml-dataprep-rslex\\\": \\\"1.2.2\\\", \\\"azureml-dataprep-native\\\": \\\"24.0.0\\\", \\\"azureml-datadrift\\\": \\\"1.17.0\\\", \\\"azureml-core\\\": \\\"1.17.0\\\", \\\"azureml-contrib-services\\\": \\\"1.17.0\\\", \\\"azureml-contrib-server\\\": \\\"1.17.0\\\", \\\"azureml-contrib-reinforcementlearning\\\": \\\"1.17.0\\\", \\\"azureml-contrib-pipeline-steps\\\": \\\"1.17.0\\\", \\\"azureml-contrib-notebook\\\": \\\"1.17.0\\\", \\\"azureml-contrib-interpret\\\": \\\"1.17.0\\\", \\\"azureml-contrib-gbdt\\\": \\\"1.17.0\\\", \\\"azureml-contrib-fairness\\\": \\\"1.17.0\\\", \\\"azureml-contrib-dataset\\\": \\\"1.17.0\\\", \\\"azureml-cli-common\\\": \\\"1.17.0\\\", \\\"azureml-automl-runtime\\\": \\\"1.17.0\\\", \\\"azureml-automl-core\\\": \\\"1.17.0\\\", \\\"azureml-accel-models\\\": \\\"1.17.0\\\"}\", \"_aml_system_scenario_identification\": \"Local.Parent\", \"ClientSdkVersion\": \"1.17.0\", \"ClientType\": \"SDK\", \"environment_cpu_name\": \"AzureML-AutoML\", \"environment_cpu_version\": \"44\", \"environment_gpu_name\": \"AzureML-AutoML-GPU\", \"environment_gpu_version\": \"32\", \"root_attribution\": \"automl\", \"attribution\": \"AutoML\", \"Orchestrator\": \"AutoML\", \"_azureml.ComputeTargetType\": \"local\", \"ProblemInfoJsonString\": \"{\\\"dataset_num_categorical\\\": 0, \\\"is_sparse\\\": true, \\\"subsampling\\\": true, \\\"dataset_classes\\\": 2, \\\"dataset_features\\\": 623416, \\\"dataset_samples\\\": 41155, \\\"single_frequency_class_detected\\\": false}\", \"feature_skus\": \"automatedml_sdk_guardrails\"}, \"tags\": {\"model_explain_run\": \"best_run\", \"best_score\": \"0.7220754010837204\", \"best_pipeline\": \"VotingEnsemble\", \"automl_best_child_run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_6\", \"model_explain_best_run_child_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_6\"}, \"end_time_utc\": \"2020-11-12T15:47:28.588747Z\", \"status\": \"Completed\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:35:10\"}, \"child_runs\": [{\"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_0\", \"run_number\": 2, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"5\", \"start_time\": \"2020-11-12T15:16:52.136067Z\", \"end_time\": \"2020-11-12T15:22:14.45618Z\", \"created_time\": \"2020-11-12T15:16:52.032994Z\", \"created_time_dt\": \"2020-11-12T15:16:52.032994Z\", \"duration\": \"0:05:22\", \"iteration\": \"0\", \"goal\": \"accuracy_max\", \"run_name\": \"MaxAbsScaler, LightGBM\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.70866253, \"best_metric\": 0.70866253}, {\"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_1\", \"run_number\": 3, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"5\", \"start_time\": \"2020-11-12T15:22:15.545236Z\", \"end_time\": \"2020-11-12T15:34:07.236401Z\", \"created_time\": \"2020-11-12T15:22:15.152762Z\", \"created_time_dt\": \"2020-11-12T15:22:15.152762Z\", \"duration\": \"0:11:52\", \"iteration\": \"1\", \"goal\": \"accuracy_max\", \"run_name\": \"MaxAbsScaler, XGBoostClassifier\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.70438618, \"best_metric\": 0.70866253}, {\"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_2\", \"run_number\": 4, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"5\", \"start_time\": \"2020-11-12T15:34:08.104958Z\", \"end_time\": \"2020-11-12T15:36:20.712146Z\", \"created_time\": \"2020-11-12T15:34:08.007743Z\", \"created_time_dt\": \"2020-11-12T15:34:08.007743Z\", \"duration\": \"0:02:12\", \"iteration\": \"2\", \"goal\": \"accuracy_max\", \"run_name\": \"MaxAbsScaler, RandomForest\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.62667982, \"best_metric\": 0.70866253}, {\"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_3\", \"run_number\": 5, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"5\", \"start_time\": \"2020-11-12T15:36:22.285465Z\", \"end_time\": \"2020-11-12T15:38:40.625944Z\", \"created_time\": \"2020-11-12T15:36:22.183604Z\", \"created_time_dt\": \"2020-11-12T15:36:22.183604Z\", \"duration\": \"0:02:18\", \"iteration\": \"3\", \"goal\": \"accuracy_max\", \"run_name\": \"MaxAbsScaler, RandomForest\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.62585365, \"best_metric\": 0.70866253}, {\"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_4\", \"run_number\": 6, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"5\", \"start_time\": \"2020-11-12T15:38:42.428085Z\", \"end_time\": \"2020-11-12T15:41:00.606719Z\", \"created_time\": \"2020-11-12T15:38:42.32492Z\", \"created_time_dt\": \"2020-11-12T15:38:42.32492Z\", \"duration\": \"0:02:18\", \"iteration\": \"4\", \"goal\": \"accuracy_max\", \"run_name\": \"MaxAbsScaler, SGD\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.70786068, \"best_metric\": 0.70866253}, {\"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_5\", \"run_number\": 7, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"5\", \"start_time\": \"2020-11-12T15:41:03.528787Z\", \"end_time\": \"2020-11-12T15:43:25.638428Z\", \"created_time\": \"2020-11-12T15:41:03.40738Z\", \"created_time_dt\": \"2020-11-12T15:41:03.40738Z\", \"duration\": \"0:02:22\", \"iteration\": \"5\", \"goal\": \"accuracy_max\", \"run_name\": \"MaxAbsScaler, SGD\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.70584399, \"best_metric\": 0.70866253}, {\"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_6\", \"run_number\": 8, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-11-12T15:43:26.093567Z\", \"end_time\": \"2020-11-12T15:45:24.532892Z\", \"created_time\": \"2020-11-12T15:43:25.996841Z\", \"created_time_dt\": \"2020-11-12T15:43:25.996841Z\", \"duration\": \"0:01:58\", \"iteration\": \"6\", \"goal\": \"accuracy_max\", \"run_name\": \"VotingEnsemble\", \"run_properties\": \"classification_labels=None,\\n                              estimators=[('0',\\n                                           Pipeline(memory=None,\\n                                                    steps=[('maxabsscaler',\\n                                                            MaxAbsScaler(copy=True\", \"primary_metric\": 0.7220754, \"best_metric\": 0.7220754}, {\"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_7\", \"run_number\": 9, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-11-12T15:45:25.244825Z\", \"end_time\": \"2020-11-12T15:47:27.731964Z\", \"created_time\": \"2020-11-12T15:45:25.13659Z\", \"created_time_dt\": \"2020-11-12T15:45:25.13659Z\", \"duration\": \"0:02:02\", \"iteration\": \"7\", \"goal\": \"accuracy_max\", \"run_name\": \"StackEnsemble\", \"run_properties\": \"base_learners=[('0',\\n                                        Pipeline(memory=None,\\n                                                 steps=[('maxabsscaler',\\n                                                         MaxAbsScaler(copy=True\", \"primary_metric\": 0.72127348, \"best_metric\": 0.7220754}], \"children_metrics\": {\"categories\": [0], \"series\": {\"f1_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"f1_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.7086625282921699, 0.7043861779866041, 0.6266798160623416, 0.6258536526977019, 0.7078606833852183, 0.7058439871646295, 0.7220754010837206, 0.7212734764731569]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"f1_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7220754010837206, 0.7220754010837206]}], \"weighted_accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"weighted_accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.7529679925933747, 0.7643255075539667, 0.7368287859118424, 0.7366191588730094, 0.7473220688930627, 0.7517966517819614, 0.7741549134018579, 0.7624861980345191]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"weighted_accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.7529679925933747, 0.7643255075539667, 0.7643255075539667, 0.7643255075539667, 0.7643255075539667, 0.7643255075539667, 0.7741549134018579, 0.7741549134018579]}], \"AUC_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"AUC_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.7757930055921928, 0.7653614285072593, 0.6808683409794392, 0.6490123287194752, 0.7800183775048729, 0.7772439819820605, 0.7944832529629485, 0.7956239056786121]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"AUC_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.7757930055921928, 0.7757930055921928, 0.7757930055921928, 0.7757930055921928, 0.7800183775048729, 0.7800183775048729, 0.7944832529629485, 0.7956239056786121]}], \"recall_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"recall_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.7086625282921699, 0.704386177986604, 0.6266798160623416, 0.6258536526977019, 0.7078606833852183, 0.7058439871646295, 0.7220754010837204, 0.7212734764731569]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"recall_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7220754010837204, 0.7220754010837204]}], \"precision_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"precision_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.7020087419821502, 0.7046724715272594, 0.6720021669347274, 0.39172975240389424, 0.7001939036932038, 0.6998654150462983, 0.7219148192350504, 0.7175933303100083]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"precision_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.7020087419821502, 0.7046724715272594, 0.7046724715272594, 0.7046724715272594, 0.7046724715272594, 0.7046724715272594, 0.7219148192350504, 0.7219148192350504]}], \"average_precision_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"average_precision_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.7514669549549847, 0.7382656934145891, 0.6280769592406711, 0.5698141233268704, 0.7589217118890824, 0.756379828140895, 0.7779233866619853, 0.777473748981205]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"average_precision_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.7514669549549847, 0.7514669549549847, 0.7514669549549847, 0.7514669549549847, 0.7589217118890824, 0.7589217118890824, 0.7779233866619853, 0.7779233866619853]}], \"average_precision_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"average_precision_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.7312971591302627, 0.7173676397102412, 0.5976777370408406, 0.5386309170246063, 0.7374310483457079, 0.7348499298120768, 0.7588310225380424, 0.7583498612677606]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"average_precision_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.7312971591302627, 0.7312971591302627, 0.7312971591302627, 0.7312971591302627, 0.7374310483457079, 0.7374310483457079, 0.7588310225380424, 0.7588310225380424]}], \"matthews_correlation\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"matthews_correlation\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.35009785670083454, 0.33347402909603224, 0.02514361479323757, 0.0, 0.35138250988846015, 0.34309224189057613, 0.3791278651871212, 0.3825229471424611]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"matthews_correlation_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.35009785670083454, 0.35009785670083454, 0.35009785670083454, 0.35009785670083454, 0.35138250988846015, 0.35138250988846015, 0.3791278651871212, 0.3825229471424611]}], \"AUC_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"AUC_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.7417540739451353, 0.7299122286373395, 0.617501394523685, 0.5494699933519529, 0.7499373480564421, 0.7474703471186755, 0.7689788958969025, 0.7684936229611897]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"AUC_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.7417540739451353, 0.7417540739451353, 0.7417540739451353, 0.7417540739451353, 0.7499373480564421, 0.7499373480564421, 0.7689788958969025, 0.7689788958969025]}], \"average_precision_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"average_precision_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.765843237011902, 0.7530412791541213, 0.6653840064800692, 0.6239536930145846, 0.7738303998992476, 0.7704704996905827, 0.7874829586913173, 0.7888201414508375]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"average_precision_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.765843237011902, 0.765843237011902, 0.765843237011902, 0.765843237011902, 0.7738303998992476, 0.7738303998992476, 0.7874829586913173, 0.7888201414508375]}], \"balanced_accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"balanced_accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.658394049661937, 0.6363476492028118, 0.5015276320584133, 0.5, 0.66307087073822, 0.6537326507021505, 0.6629788315404861, 0.6745656308313356]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"balanced_accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.658394049661937, 0.658394049661937, 0.658394049661937, 0.658394049661937, 0.66307087073822, 0.66307087073822, 0.66307087073822, 0.6745656308313356]}], \"log_loss\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"log_loss\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.6489426155649136, 0.5798151118147867, 0.6480847553032668, 0.6602593994242768, 0.5728077623528594, 0.5667381507719166, 0.5497607266316361, 0.5495289443659681]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"log_loss_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.6489426155649136, 0.5798151118147867, 0.5798151118147867, 0.5798151118147867, 0.5728077623528594, 0.5667381507719166, 0.5497607266316361, 0.5495289443659681]}], \"precision_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"precision_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.7086625282921699, 0.704386177986604, 0.6266798160623416, 0.6258536526977019, 0.7078606833852183, 0.7058439871646295, 0.7220754010837204, 0.7212734764731569]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"precision_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7220754010837204, 0.7220754010837204]}], \"norm_macro_recall\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"norm_macro_recall\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.3167880993238741, 0.27269529840562373, 0.0030552641168267356, 0.0, 0.32614174147644, 0.307465301404301, 0.32595766308097235, 0.3491312616626714]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"norm_macro_recall_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.3167880993238741, 0.3167880993238741, 0.3167880993238741, 0.3167880993238741, 0.32614174147644, 0.32614174147644, 0.32614174147644, 0.3491312616626714]}], \"recall_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"recall_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.7086625282921699, 0.7043861779866041, 0.6266798160623416, 0.6258536526977019, 0.7078606833852183, 0.7058439871646295, 0.7220754010837204, 0.7212734764731569]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"recall_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7220754010837204, 0.7220754010837204]}], \"f1_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"f1_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.694167030068055, 0.6757580330167818, 0.48512234633568857, 0.48184751017687494, 0.6969888589481273, 0.6895804201836823, 0.7013821845549338, 0.7082051131806087]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"f1_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.694167030068055, 0.694167030068055, 0.694167030068055, 0.694167030068055, 0.6969888589481273, 0.6969888589481273, 0.7013821845549338, 0.7082051131806087]}], \"recall_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"recall_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.658394049661937, 0.6363476492028118, 0.5015276320584133, 0.5, 0.66307087073822, 0.6537326507021505, 0.6629788315404861, 0.6745656308313356]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"recall_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.658394049661937, 0.658394049661937, 0.658394049661937, 0.658394049661937, 0.66307087073822, 0.66307087073822, 0.66307087073822, 0.6745656308313356]}], \"AUC_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"AUC_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.7417540739451353, 0.7299122285734495, 0.617501394523685, 0.5494699933519529, 0.7499373480564421, 0.7474703471186755, 0.768978896843012, 0.7684936229611897]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"AUC_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.7417540739451353, 0.7417540739451353, 0.7417540739451353, 0.7417540739451353, 0.7499373480564421, 0.7499373480564421, 0.768978896843012, 0.768978896843012]}], \"accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.7086625282921699, 0.704386177986604, 0.6266798160623416, 0.6258536526977019, 0.7078606833852183, 0.7058439871646295, 0.7220754010837204, 0.7212734764731569]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7086625282921699, 0.7220754010837204, 0.7220754010837204]}], \"f1_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"f1_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.6631342367899973, 0.6363124761853659, 0.3892563966347052, 0.3849298976092643, 0.6681589472551991, 0.6574329044286765, 0.667733281792699, 0.6793706284307209]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"f1_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.6631342367899973, 0.6631342367899973, 0.6631342367899973, 0.6631342367899973, 0.6681589472551991, 0.6681589472551991, 0.6681589472551991, 0.6793706284307209]}], \"precision_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"markers\", \"name\": \"precision_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.693658722946242, 0.7042833779278631, 0.6856755690059173, 0.31292682634885094, 0.6893424290607438, 0.6919191926222403, 0.7208752801579313, 0.710234466339316]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], \"mode\": \"lines\", \"name\": \"precision_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.693658722946242, 0.7042833779278631, 0.7042833779278631, 0.7042833779278631, 0.7042833779278631, 0.7042833779278631, 0.7208752801579313, 0.7208752801579313]}]}, \"metricName\": null, \"primaryMetricName\": \"accuracy\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"experiment_status\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"series\": [{\"data\": [\"DatasetEvaluation\", \"FeaturesGeneration\", \"DatasetFeaturization\", \"DatasetFeaturizationCompleted\", \"DatasetCrossValidationSplit\", \"ModelSelection\", \"BestRunExplainModel\", \"ModelExplanationDataSetSetup\", \"PickSurrogateModel\", \"EngineeredFeatureExplanations\", \"EngineeredFeatureExplanations\", \"BestRunExplainModel\"]}]}, {\"name\": \"experiment_status_description\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"series\": [{\"data\": [\"Gathering dataset statistics.\", \"Generating features for the dataset.\", \"Beginning to fit featurizers and featurize the dataset.\", \"Completed fit featurizers and featurizing the dataset.\", \"Generating individually featurized CV splits.\", \"Beginning model selection.\", \"Best run model explanations started\", \"Model explanations data setup completed\", \"Choosing LinearModel as the surrogate model for explanations\", \"Computation of engineered features started\", \"Computation of engineered features completed\", \"Best run model explanations completed\"]}]}, {\"name\": \"f1_score_micro\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.7220754010837206]}]}, {\"name\": \"weighted_accuracy\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.7741549134018579]}]}, {\"name\": \"AUC_micro\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.7944832529629485]}]}, {\"name\": \"recall_score_micro\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.7220754010837204]}]}, {\"name\": \"precision_score_weighted\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.7219148192350504]}]}, {\"name\": \"average_precision_score_weighted\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.7779233866619853]}]}, {\"name\": \"average_precision_score_macro\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.7588310225380424]}]}, {\"name\": \"matthews_correlation\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.3791278651871212]}]}, {\"name\": \"AUC_macro\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.7689788958969025]}]}, {\"name\": \"average_precision_score_micro\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.7874829586913173]}]}, {\"name\": \"balanced_accuracy\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.6629788315404861]}]}, {\"name\": \"log_loss\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.5497607266316361]}]}, {\"name\": \"precision_score_micro\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.7220754010837204]}]}, {\"name\": \"norm_macro_recall\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.32595766308097235]}]}, {\"name\": \"recall_score_weighted\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.7220754010837204]}]}, {\"name\": \"f1_score_weighted\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.7013821845549338]}]}, {\"name\": \"recall_score_macro\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.6629788315404861]}]}, {\"name\": \"AUC_weighted\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.768978896843012]}]}, {\"name\": \"accuracy\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.7220754010837204]}]}, {\"name\": \"f1_score_macro\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.667733281792699]}]}, {\"name\": \"precision_score_macro\", \"run_id\": \"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0\", \"categories\": [0], \"series\": [{\"data\": [0.7208752801579313]}]}], \"run_logs\": \"\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.17.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "{'runId': 'AutoML_abbda561-5be6-424f-8561-456ebc80c7c0',\n 'target': 'local',\n 'status': 'Completed',\n 'startTimeUtc': '2020-11-12T15:12:20.183404Z',\n 'endTimeUtc': '2020-11-12T15:47:28.588747Z',\n 'properties': {'num_iterations': '1000',\n  'training_type': 'TrainFull',\n  'acquisition_function': 'EI',\n  'primary_metric': 'accuracy',\n  'train_split': '0',\n  'acquisition_parameter': '0',\n  'num_cross_validation': '3',\n  'target': 'local',\n  'AMLSettingsJsonString': '{\"path\":null,\"name\":\"capstone-automl\",\"subscription_id\":\"174c6bee-3e04-4ee5-98ea-6d411844e6dd\",\"resource_group\":\"aml-quickstarts-125813\",\"workspace_name\":\"quick-starts-ws-125813\",\"region\":\"southcentralus\",\"compute_target\":\"local\",\"spark_service\":null,\"azure_service\":\"Microsoft.AzureNotebookVM\",\"_local_managed_run_id\":null,\"many_models\":false,\"pipeline_fetch_max_batch_size\":1,\"iterations\":1000,\"primary_metric\":\"accuracy\",\"task_type\":\"classification\",\"data_script\":null,\"validation_size\":0.0,\"n_cross_validations\":3,\"y_min\":null,\"y_max\":null,\"num_classes\":2,\"featurization\":\"auto\",\"_ignore_package_version_incompatibilities\":false,\"is_timeseries\":false,\"max_cores_per_iteration\":1,\"max_concurrent_iterations\":1,\"iteration_timeout_minutes\":null,\"mem_in_mb\":null,\"enforce_time_on_windows\":false,\"experiment_timeout_minutes\":30,\"experiment_exit_score\":null,\"whitelist_models\":null,\"blacklist_algos\":[\"TensorFlowLinearClassifier\",\"TensorFlowDNN\"],\"supported_models\":[\"SGD\",\"BernoulliNaiveBayes\",\"LightGBM\",\"LogisticRegression\",\"DecisionTree\",\"GradientBoosting\",\"TensorFlowDNN\",\"RandomForest\",\"KNN\",\"TensorFlowLinearClassifier\",\"XGBoostClassifier\",\"MultinomialNaiveBayes\",\"LinearSVM\",\"AveragedPerceptronClassifier\",\"ExtremeRandomTrees\",\"SVM\"],\"auto_blacklist\":true,\"blacklist_samples_reached\":false,\"exclude_nan_labels\":true,\"verbosity\":20,\"_debug_log\":\"automl.log\",\"show_warnings\":false,\"model_explainability\":true,\"service_url\":null,\"sdk_url\":null,\"sdk_packages\":null,\"enable_onnx_compatible_models\":false,\"enable_split_onnx_featurizer_estimator_models\":false,\"vm_type\":null,\"telemetry_verbosity\":20,\"send_telemetry\":true,\"enable_dnn\":false,\"force_text_dnn\":false,\"enable_feature_sweeping\":true,\"enable_early_stopping\":false,\"early_stopping_n_iters\":10,\"metrics\":null,\"enable_ensembling\":true,\"enable_stack_ensembling\":true,\"ensemble_iterations\":15,\"enable_tf\":false,\"enable_subsampling\":null,\"subsample_seed\":null,\"enable_nimbusml\":false,\"enable_streaming\":false,\"force_streaming\":false,\"track_child_runs\":true,\"allowed_private_models\":[],\"label_column_name\":\"Sentiment\",\"weight_column_name\":null,\"cv_split_column_names\":null,\"enable_local_managed\":false,\"cost_mode\":1,\"lag_length\":0,\"metric_operation\":\"maximize\",\"preprocess\":true,\"scenario\":\"SDK-1.13.0\"}',\n  'DataPrepJsonString': None,\n  'EnableSubsampling': None,\n  'runTemplate': 'AutoML',\n  'azureml.runsource': 'automl',\n  'display_task_type': 'classification',\n  'dependencies_versions': '{\"azureml-widgets\": \"1.17.0\", \"azureml-train\": \"1.17.0\", \"azureml-train-restclients-hyperdrive\": \"1.17.0\", \"azureml-train-core\": \"1.17.0\", \"azureml-train-automl\": \"1.17.0\", \"azureml-train-automl-runtime\": \"1.17.0\", \"azureml-train-automl-client\": \"1.17.0\", \"azureml-tensorboard\": \"1.17.0\", \"azureml-telemetry\": \"1.17.0\", \"azureml-sdk\": \"1.17.0\", \"azureml-samples\": \"0+unknown\", \"azureml-pipeline\": \"1.17.0\", \"azureml-pipeline-steps\": \"1.17.0\", \"azureml-pipeline-core\": \"1.17.0\", \"azureml-opendatasets\": \"1.17.0\", \"azureml-model-management-sdk\": \"1.0.1b6.post1\", \"azureml-mlflow\": \"1.17.0.post1\", \"azureml-interpret\": \"1.17.0\", \"azureml-explain-model\": \"1.17.0\", \"azureml-defaults\": \"1.17.0\", \"azureml-dataset-runtime\": \"1.17.0\", \"azureml-dataprep\": \"2.4.2\", \"azureml-dataprep-rslex\": \"1.2.2\", \"azureml-dataprep-native\": \"24.0.0\", \"azureml-datadrift\": \"1.17.0\", \"azureml-core\": \"1.17.0\", \"azureml-contrib-services\": \"1.17.0\", \"azureml-contrib-server\": \"1.17.0\", \"azureml-contrib-reinforcementlearning\": \"1.17.0\", \"azureml-contrib-pipeline-steps\": \"1.17.0\", \"azureml-contrib-notebook\": \"1.17.0\", \"azureml-contrib-interpret\": \"1.17.0\", \"azureml-contrib-gbdt\": \"1.17.0\", \"azureml-contrib-fairness\": \"1.17.0\", \"azureml-contrib-dataset\": \"1.17.0\", \"azureml-cli-common\": \"1.17.0\", \"azureml-automl-runtime\": \"1.17.0\", \"azureml-automl-core\": \"1.17.0\", \"azureml-accel-models\": \"1.17.0\"}',\n  '_aml_system_scenario_identification': 'Local.Parent',\n  'ClientSdkVersion': '1.17.0',\n  'ClientType': 'SDK',\n  'environment_cpu_name': 'AzureML-AutoML',\n  'environment_cpu_version': '44',\n  'environment_gpu_name': 'AzureML-AutoML-GPU',\n  'environment_gpu_version': '32',\n  'root_attribution': 'automl',\n  'attribution': 'AutoML',\n  'Orchestrator': 'AutoML',\n  '_azureml.ComputeTargetType': 'local',\n  'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": true, \"subsampling\": true, \"dataset_classes\": 2, \"dataset_features\": 623416, \"dataset_samples\": 41155, \"single_frequency_class_detected\": false}',\n  'feature_skus': 'automatedml_sdk_guardrails'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'logFiles': {}}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1605196193685
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_run_automl, best_model_automl = automl_run.get_output()\n",
        "best_run_metrics = best_run_automl.get_metrics()\n",
        "parameter_values = best_run_automl.get_details()\n",
        "\n",
        "print(\"Best Run Id: \", best_run_automl.id)\n",
        "print(\"\\n\")\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy: \", best_run_metrics[\"accuracy\"])\n",
        "print(\"\\n\")\n",
        "print(\"\\n\")\n",
        "print(\"Parameters: \", parameter_values)\n",
        "print(\"\\n\")\n",
        "print(\"\\n\")\n",
        "print(\"Metrics for best run: \", best_run_automl.get_metrics())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Run Id:  AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_6\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Accuracy:  0.7220754010837204\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Parameters:  {'runId': 'AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_6', 'status': 'Completed', 'startTimeUtc': '2020-11-12T15:43:26.093567Z', 'endTimeUtc': '2020-11-12T15:45:24.532892Z', 'properties': {'runTemplate': 'automl_child', 'pipeline_id': '__AutoML_Ensemble__', 'pipeline_spec': '{\"pipeline_id\":\"__AutoML_Ensemble__\",\"objects\":[{\"module\":\"azureml.train.automl.ensemble\",\"class_name\":\"Ensemble\",\"spec_class\":\"sklearn\",\"param_args\":[],\"param_kwargs\":{\"automl_settings\":\"{\\'task_type\\':\\'classification\\',\\'primary_metric\\':\\'accuracy\\',\\'verbosity\\':20,\\'ensemble_iterations\\':15,\\'is_timeseries\\':False,\\'name\\':\\'capstone-automl\\',\\'compute_target\\':\\'local\\',\\'subscription_id\\':\\'174c6bee-3e04-4ee5-98ea-6d411844e6dd\\',\\'region\\':\\'southcentralus\\',\\'spark_service\\':None}\",\"ensemble_run_id\":\"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_6\",\"experiment_name\":null,\"workspace_name\":\"quick-starts-ws-125813\",\"subscription_id\":\"174c6bee-3e04-4ee5-98ea-6d411844e6dd\",\"resource_group_name\":\"aml-quickstarts-125813\"}}]}', 'training_percent': '100', 'predicted_cost': None, 'iteration': '6', '_azureml.ComputeTargetType': 'local', '_aml_system_scenario_identification': 'Local.Child', 'run_template': 'automl_child', 'run_preprocessor': '', 'run_algorithm': 'VotingEnsemble', 'conda_env_data_location': 'aml://artifact/ExperimentRun/dcid.AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_6/outputs/conda_env_v_1_0_0.yml', 'model_data_location': 'aml://artifact/ExperimentRun/dcid.AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_6/outputs/model.pkl', 'model_size_on_disk': '133381986', 'scoring_data_location': 'aml://artifact/ExperimentRun/dcid.AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_6/outputs/scoring_file_v_1_0_0.py', 'model_exp_support': 'True', 'pipeline_graph_version': '1.0.0', 'model_name': 'AutoMLabbda56156', 'staticProperties': '{}', 'score': '0.7220754010837204', 'run_properties': \"classification_labels=None,\\n                              estimators=[('0',\\n                                           Pipeline(memory=None,\\n                                                    steps=[('maxabsscaler',\\n                                                            MaxAbsScaler(copy=True\", 'pipeline_script': '{\"pipeline_id\":\"__AutoML_Ensemble__\",\"objects\":[{\"module\":\"azureml.train.automl.ensemble\",\"class_name\":\"Ensemble\",\"spec_class\":\"sklearn\",\"param_args\":[],\"param_kwargs\":{\"automl_settings\":\"{\\'task_type\\':\\'classification\\',\\'primary_metric\\':\\'accuracy\\',\\'verbosity\\':20,\\'ensemble_iterations\\':15,\\'is_timeseries\\':False,\\'name\\':\\'capstone-automl\\',\\'compute_target\\':\\'local\\',\\'subscription_id\\':\\'174c6bee-3e04-4ee5-98ea-6d411844e6dd\\',\\'region\\':\\'southcentralus\\',\\'spark_service\\':None}\",\"ensemble_run_id\":\"AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_6\",\"experiment_name\":null,\"workspace_name\":\"quick-starts-ws-125813\",\"subscription_id\":\"174c6bee-3e04-4ee5-98ea-6d411844e6dd\",\"resource_group_name\":\"aml-quickstarts-125813\"}}]}', 'training_type': 'MeanCrossValidation', 'num_classes': '2', 'framework': 'sklearn', 'fit_time': '87', 'goal': 'accuracy_max', 'class_labels': '', 'primary_metric': 'accuracy', 'errors': '{}', 'fitted_pipeline': \"Pipeline(memory=None,\\n         steps=[('datatransformer',\\n                 DataTransformer(allow_chargram=None, enable_dnn=None,\\n                                 enable_feature_sweeping=None,\\n                                 feature_sweeping_config=None,\\n                                 feature_sweeping_timeout=None,\\n                                 featurization_config=None, force_text_dnn=None,\\n                                 is_cross_validation=None,\\n                                 is_onnx_compatible=None, logger=None,\\n                                 observer=None, task=None, working_dir=None)),\\n                ('prefittedso...\\n                                                                                               n_estimators=100,\\n                                                                                               n_jobs=1,\\n                                                                                               nthread=None,\\n                                                                                               objective='binary:logistic',\\n                                                                                               random_state=0,\\n                                                                                               reg_alpha=0,\\n                                                                                               reg_lambda=1,\\n                                                                                               scale_pos_weight=1,\\n                                                                                               seed=None,\\n                                                                                               silent=None,\\n                                                                                               subsample=1,\\n                                                                                               tree_method='auto',\\n                                                                                               verbose=-10,\\n                                                                                               verbosity=0))],\\n                                                                     verbose=False))],\\n                                               flatten_transform=None,\\n                                               weights=[0.18181818181818182,\\n                                                        0.18181818181818182,\\n                                                        0.2727272727272727,\\n                                                        0.36363636363636365]))],\\n         verbose=False)\", 'friendly_errors': '{}', 'onnx_model_resource': '{}', 'error_code': '', 'failure_reason': '', 'feature_skus': 'automatedml_sdk_guardrails', 'dependencies_versions': '{\"azureml-widgets\": \"1.17.0\", \"azureml-train\": \"1.17.0\", \"azureml-train-restclients-hyperdrive\": \"1.17.0\", \"azureml-train-core\": \"1.17.0\", \"azureml-train-automl\": \"1.17.0\", \"azureml-train-automl-runtime\": \"1.17.0\", \"azureml-train-automl-client\": \"1.17.0\", \"azureml-tensorboard\": \"1.17.0\", \"azureml-telemetry\": \"1.17.0\", \"azureml-sdk\": \"1.17.0\", \"azureml-samples\": \"0+unknown\", \"azureml-pipeline\": \"1.17.0\", \"azureml-pipeline-steps\": \"1.17.0\", \"azureml-pipeline-core\": \"1.17.0\", \"azureml-opendatasets\": \"1.17.0\", \"azureml-model-management-sdk\": \"1.0.1b6.post1\", \"azureml-mlflow\": \"1.17.0.post1\", \"azureml-interpret\": \"1.17.0\", \"azureml-explain-model\": \"1.17.0\", \"azureml-defaults\": \"1.17.0\", \"azureml-dataset-runtime\": \"1.17.0\", \"azureml-dataprep\": \"2.4.2\", \"azureml-dataprep-rslex\": \"1.2.2\", \"azureml-dataprep-native\": \"24.0.0\", \"azureml-datadrift\": \"1.17.0\", \"azureml-core\": \"1.17.0\", \"azureml-contrib-services\": \"1.17.0\", \"azureml-contrib-server\": \"1.17.0\", \"azureml-contrib-reinforcementlearning\": \"1.17.0\", \"azureml-contrib-pipeline-steps\": \"1.17.0\", \"azureml-contrib-notebook\": \"1.17.0\", \"azureml-contrib-interpret\": \"1.17.0\", \"azureml-contrib-gbdt\": \"1.17.0\", \"azureml-contrib-fairness\": \"1.17.0\", \"azureml-contrib-dataset\": \"1.17.0\", \"azureml-cli-common\": \"1.17.0\", \"azureml-automl-runtime\": \"1.17.0\", \"azureml-automl-core\": \"1.17.0\", \"azureml-accel-models\": \"1.17.0\"}', 'num_cores': '4', 'num_logical_cores': '4', 'peak_memory_usage': '8357508', 'vm_configuration': 'Intel(R) Xeon(R) Platinum 8171M CPU @ 2.60GHz', 'core_hours': '0.03762430111111112'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {}}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Metrics for best run:  {'f1_score_micro': 0.7220754010837206, 'weighted_accuracy': 0.7741549134018579, 'AUC_micro': 0.7944832529629485, 'recall_score_micro': 0.7220754010837204, 'precision_score_weighted': 0.7219148192350504, 'average_precision_score_weighted': 0.7779233866619853, 'average_precision_score_macro': 0.7588310225380424, 'matthews_correlation': 0.3791278651871212, 'AUC_macro': 0.7689788958969025, 'average_precision_score_micro': 0.7874829586913173, 'balanced_accuracy': 0.6629788315404861, 'log_loss': 0.5497607266316361, 'precision_score_micro': 0.7220754010837204, 'norm_macro_recall': 0.32595766308097235, 'recall_score_weighted': 0.7220754010837204, 'f1_score_weighted': 0.7013821845549338, 'recall_score_macro': 0.6629788315404861, 'AUC_weighted': 0.768978896843012, 'accuracy': 0.7220754010837204, 'f1_score_macro': 0.667733281792699, 'precision_score_macro': 0.7208752801579313, 'accuracy_table': 'aml://artifactId/ExperimentRun/dcid.AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_6/accuracy_table', 'confusion_matrix': 'aml://artifactId/ExperimentRun/dcid.AutoML_abbda561-5be6-424f-8561-456ebc80c7c0_6/confusion_matrix'}\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1605196209859
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# referencce - https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.run.automlrun?view=azure-ml-py\n",
        "print(best_model_automl.steps[-1])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('prefittedsoftvotingclassifier', PreFittedSoftVotingClassifier(classification_labels=None,\n",
            "                              estimators=[('0',\n",
            "                                           Pipeline(memory=None,\n",
            "                                                    steps=[('maxabsscaler',\n",
            "                                                            MaxAbsScaler(copy=True)),\n",
            "                                                           ('lightgbmclassifier',\n",
            "                                                            LightGBMClassifier(boosting_type='gbdt',\n",
            "                                                                               class_weight=None,\n",
            "                                                                               colsample_bytree=1.0,\n",
            "                                                                               importance_type='split',\n",
            "                                                                               learning_rate=0.1,\n",
            "                                                                               max_depth=-1,\n",
            "                                                                               min_child_samples=20,\n",
            "                                                                               min_child_weight=0.001,\n",
            "                                                                               min_spl...\n",
            "                                                                              min_child_weight=1,\n",
            "                                                                              missing=nan,\n",
            "                                                                              n_estimators=100,\n",
            "                                                                              n_jobs=1,\n",
            "                                                                              nthread=None,\n",
            "                                                                              objective='binary:logistic',\n",
            "                                                                              random_state=0,\n",
            "                                                                              reg_alpha=0,\n",
            "                                                                              reg_lambda=1,\n",
            "                                                                              scale_pos_weight=1,\n",
            "                                                                              seed=None,\n",
            "                                                                              silent=None,\n",
            "                                                                              subsample=1,\n",
            "                                                                              tree_method='auto',\n",
            "                                                                              verbose=-10,\n",
            "                                                                              verbosity=0))],\n",
            "                                                    verbose=False))],\n",
            "                              flatten_transform=None,\n",
            "                              weights=[0.18181818181818182, 0.18181818181818182,\n",
            "                                       0.2727272727272727,\n",
            "                                       0.36363636363636365]))\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1605196210090
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Personal ToDo - Check why can't register model from get_output() directly\n",
        "best_model_automl = best_run_automl.register_model(model_name=\"automl_model_best\", model_path=\"./outputs\")"
      ],
      "outputs": [],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1605201117062
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_automl.download(exist_ok=True)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "''"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1605196217813
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference - https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=python#define-an-inference-configuration\n",
        "\n",
        "# Selecting curated environment as per - https://docs.microsoft.com/en-us/azure/machine-learning/resource-curated-environments\n",
        "env = Environment.get(ws, \"AzureML-AutoML\").clone(\"automl-env\")\n",
        "\n",
        "inference_config = InferenceConfig(entry_script='score.py', environment=env)\n",
        "\n",
        "# Reference - https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice.aci.aciwebservice?view=azure-ml-py\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=4)\n",
        "\n",
        "service = best_model_automl.deploy(\n",
        "    workspace=ws,\n",
        "    name=\"automl-deployment\",\n",
        "    models=[best_model_automl],\n",
        "    inference_config=inference_config,\n",
        "    deployment_config=aci_config,\n",
        "    overwrite=True\n",
        ")\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running.......................................\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n"
          ]
        }
      ],
      "execution_count": 54,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605204709780
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service.update(enable_app_insights=True)"
      ],
      "outputs": [],
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1605204743946
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tweet_json = json.dumps({'data':[df_modified.loc[0, \"OriginalTweet\"]]})\n",
        "# Reference - https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice.webservice.webservice?view=azure-ml-py&preserve-view=true#run-input-\n",
        "output = service.run(bytes(input_tweet_json, encoding=\"utf8\"))\n",
        "print(\"Predicted Sentiment: \", output)\n",
        "print(\"Actual Sentiment: \", df_modified[\"Sentiment\"][0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Sentiment:  Must pass 2-d input\n",
            "Actual Sentiment:  1\n"
          ]
        }
      ],
      "execution_count": 66,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605205915343
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020-11-12T17:34:34,767330984+00:00 - iot-server/run \n",
            "2020-11-12T17:34:34,776633427+00:00 - gunicorn/run \n",
            "2020-11-12T17:34:34,773103211+00:00 - rsyslog/run \n",
            "2020-11-12T17:34:34,790724793+00:00 - nginx/run \n",
            "/usr/sbin/nginx: /azureml-envs/azureml_51fe5b7aeae94a7d55cb14fbfa8da056/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_51fe5b7aeae94a7d55cb14fbfa8da056/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_51fe5b7aeae94a7d55cb14fbfa8da056/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_51fe5b7aeae94a7d55cb14fbfa8da056/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_51fe5b7aeae94a7d55cb14fbfa8da056/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "rsyslogd: /azureml-envs/azureml_51fe5b7aeae94a7d55cb14fbfa8da056/lib/libuuid.so.1: no version information available (required by rsyslogd)\n",
            "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
            "2020-11-12T17:34:34,923155711+00:00 - iot-server/finish 1 0\n",
            "2020-11-12T17:34:34,924993819+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
            "Starting gunicorn 19.9.0\n",
            "Listening at: http://127.0.0.1:31311 (15)\n",
            "Using worker: sync\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 39\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:34:35,423 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:34:35,424 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:34:35,424 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:34:35,424 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "Generating new fontManager, this may take some time...\n",
            "2020-11-12 17:34:57,905 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 52\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:34:58,272 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:34:58,272 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:34:58,272 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:34:58,272 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:35:20,962 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 62\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:35:21,327 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:35:21,327 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:35:21,328 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:35:21,328 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:35:43,519 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 72\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:35:43,849 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:35:43,849 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:35:43,850 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:35:43,850 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:36:05,402 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 82\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:36:05,742 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:36:05,742 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:36:05,743 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:36:05,743 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:36:28,085 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 92\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:36:28,419 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:36:28,419 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:36:28,419 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:36:28,419 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:36:50,255 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 102\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:36:50,598 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:36:50,599 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:36:50,599 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:36:50,599 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:37:12,519 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 112\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:37:12,838 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:37:12,838 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:37:12,838 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:37:12,839 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:37:34,914 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 122\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:37:35,258 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:37:35,258 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:37:35,258 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:37:35,259 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:37:57,775 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 132\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:37:58,151 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:37:58,151 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:37:58,152 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:37:58,152 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:38:20,260 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 142\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:38:20,578 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:38:20,578 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:38:20,578 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:38:20,578 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:38:42,662 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 152\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:38:42,994 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:38:42,994 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:38:42,994 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:38:42,994 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:39:04,941 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 162\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:39:05,280 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:39:05,280 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:39:05,280 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:39:05,280 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:39:27,843 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 172\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:39:28,172 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:39:28,172 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:39:28,172 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:39:28,172 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:39:50,521 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 182\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:39:50,849 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:39:50,849 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:39:50,849 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:39:50,849 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:40:13,289 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 192\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:40:13,632 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:40:13,633 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:40:13,633 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:40:13,633 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:40:36,217 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 202\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:40:36,539 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:40:36,539 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:40:36,539 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:40:36,540 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:40:58,305 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 212\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:40:58,641 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:40:58,641 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:40:58,641 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:40:58,641 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:41:21,056 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 222\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:41:21,405 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:41:21,406 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:41:21,406 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:41:21,406 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:41:44,500 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 232\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:41:44,837 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:41:44,837 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:41:44,837 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:41:44,838 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:42:06,619 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 242\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:42:06,961 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:42:06,961 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:42:06,961 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:42:06,961 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:42:29,372 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 252\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:42:29,723 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:42:29,724 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:42:29,724 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:42:29,724 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:42:52,181 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 262\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:42:52,542 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:42:52,542 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:42:52,543 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:42:52,543 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:43:14,586 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 272\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:43:14,932 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:43:14,932 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:43:14,933 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:43:14,933 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:43:36,860 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 282\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:43:37,174 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:43:37,174 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:43:37,174 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:43:37,175 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:43:59,357 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 292\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:43:59,722 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:43:59,722 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:43:59,722 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:43:59,722 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:44:22,689 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 302\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:44:23,033 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:44:23,034 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:44:23,034 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:44:23,034 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:44:45,555 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 312\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:44:45,915 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:44:45,916 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:44:45,916 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:44:45,916 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:45:08,403 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 322\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:45:08,744 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:45:08,744 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:45:08,744 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:45:08,745 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:45:31,335 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 332\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:45:31,680 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:45:31,680 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:45:31,680 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:45:31,680 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:45:54,107 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 342\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:45:54,429 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:45:54,429 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:45:54,430 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:45:54,430 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:46:16,905 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 352\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:46:17,264 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:46:17,264 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:46:17,264 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:46:17,265 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:46:39,617 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 362\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:46:39,981 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:46:39,981 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:46:39,981 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:46:39,981 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:47:01,975 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 372\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:47:02,336 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:47:02,336 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:47:02,336 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:47:02,337 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:47:24,666 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 382\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:47:24,990 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:47:24,990 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:47:24,990 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:47:24,990 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:47:47,025 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 392\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:47:47,370 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:47:47,370 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:47:47,371 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:47:47,371 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:48:09,421 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 402\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:48:09,773 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:48:09,773 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:48:09,774 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:48:09,774 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:48:32,530 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 412\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:48:32,864 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:48:32,864 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:48:32,864 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:48:32,864 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:48:55,801 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 422\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:48:56,135 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:48:56,135 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:48:56,135 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:48:56,135 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:49:19,257 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 432\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:49:19,575 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:49:19,575 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:49:19,576 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:49:19,576 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:49:41,319 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 442\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:49:41,703 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:49:41,703 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:49:41,704 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:49:41,704 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:50:04,529 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 452\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:50:04,894 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:50:04,894 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:50:04,894 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:50:04,894 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:50:27,817 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 462\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:50:28,147 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:50:28,147 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:50:28,147 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:50:28,147 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:50:50,407 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 472\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:50:50,743 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:50:50,743 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:50:50,743 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:50:50,743 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:51:13,439 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 482\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:51:13,789 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:51:13,790 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:51:13,790 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:51:13,790 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:51:35,800 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 492\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:51:36,138 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:51:36,138 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:51:36,139 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:51:36,139 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:51:57,688 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 502\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:51:58,060 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:51:58,060 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:51:58,060 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:51:58,060 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:52:20,805 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 512\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:52:21,167 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:52:21,167 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:52:21,167 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:52:21,167 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:52:42,936 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 522\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:52:43,295 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:52:43,295 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:52:43,295 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:52:43,295 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:53:04,752 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 532\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:53:05,082 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:53:05,082 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:53:05,083 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:53:05,083 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:53:27,165 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 542\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:53:27,512 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:53:27,513 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:53:27,513 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:53:27,513 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:53:49,143 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 552\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:53:49,471 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:53:49,472 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:53:49,472 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:53:49,472 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:54:11,679 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 562\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:54:12,036 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:54:12,036 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:54:12,036 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:54:12,036 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:54:34,185 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 572\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:54:34,530 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:54:34,530 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:54:34,530 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:54:34,530 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2020-11-12 17:54:56,173 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 582\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2020-11-12 17:54:56,509 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2020-11-12 17:54:56,509 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2020-11-12 17:54:56,510 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2020-11-12 17:54:56,510 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "\n"
          ]
        }
      ],
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1605203706993
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#service.delete()"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605200622042
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(\"./outputs/model.pkl\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['conda_env_v_1_0_0.yml', 'env_dependencies.json', 'model.pkl', 'pipeline_graph.json', 'scoring_file_v_1_0_0.py']\n"
          ]
        }
      ],
      "execution_count": 43,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605200731893
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "widgets": {
      "state": {},
      "version": "1.1.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}